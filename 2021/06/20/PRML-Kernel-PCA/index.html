<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"lsx-sneakerprogrammer.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="前言好久没写博客了，之前一直在做RelexNet的项目，感觉上是做出了一些还不错的东西，也不知道能不能发一篇论文。这个学期选了anu Statistic Machine Learning这门以前的神课，当然感觉现在好像没有以前那种难度的感觉了，但结合这门课加上PRML这本书的学习，也从数学的角度更好的理解了一些机器学习的原理，不得不说Bishop是真的很爱用贝叶斯来解释一切。 PrefaceIt">
<meta property="og:type" content="article">
<meta property="og:title" content="PRML-Kernel PCA">
<meta property="og:url" content="https://lsx-sneakerprogrammer.github.io/2021/06/20/PRML-Kernel-PCA/index.html">
<meta property="og:site_name" content="永缘空的博客">
<meta property="og:description" content="前言好久没写博客了，之前一直在做RelexNet的项目，感觉上是做出了一些还不错的东西，也不知道能不能发一篇论文。这个学期选了anu Statistic Machine Learning这门以前的神课，当然感觉现在好像没有以前那种难度的感觉了，但结合这门课加上PRML这本书的学习，也从数学的角度更好的理解了一些机器学习的原理，不得不说Bishop是真的很爱用贝叶斯来解释一切。 PrefaceIt">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lsx-sneakerprogrammer.github.io/2021/06/20/PRML-Kernel-PCA/1.png">
<meta property="og:image" content="https://lsx-sneakerprogrammer.github.io/2021/06/20/PRML-Kernel-PCA/2.png">
<meta property="og:image" content="https://lsx-sneakerprogrammer.github.io/2021/06/20/PRML-Kernel-PCA/3.png">
<meta property="og:image" content="https://lsx-sneakerprogrammer.github.io/2021/06/20/PRML-Kernel-PCA/6.png">
<meta property="og:image" content="https://lsx-sneakerprogrammer.github.io/2021/06/20/PRML-Kernel-PCA/7.png">
<meta property="og:image" content="https://lsx-sneakerprogrammer.github.io/2021/06/20/PRML-Kernel-PCA/8.png">
<meta property="article:published_time" content="2021-06-19T17:05:11.000Z">
<meta property="article:modified_time" content="2021-07-20T12:00:12.913Z">
<meta property="article:author" content="永缘空">
<meta property="article:tag" content="course">
<meta property="article:tag" content="ml">
<meta property="article:tag" content="prml">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lsx-sneakerprogrammer.github.io/2021/06/20/PRML-Kernel-PCA/1.png">

<link rel="canonical" href="https://lsx-sneakerprogrammer.github.io/2021/06/20/PRML-Kernel-PCA/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>PRML-Kernel PCA | 永缘空的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>


<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>


<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">永缘空的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">学习生活记录</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签<span class="badge">12</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类<span class="badge">7</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档<span class="badge">12</span></a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lsx-sneakerprogrammer.github.io/2021/06/20/PRML-Kernel-PCA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.jpg">
      <meta itemprop="name" content="永缘空">
      <meta itemprop="description" content="山东大学17级计算机科学与技术，澳大利亚国立大学Bachelor of Advanced Computing(Honors), 澳大利亚国立大学Master of Machine Learning and Computer Vision主要学习NLP, Machine Learning等机器学习领域，此为个人博客。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="永缘空的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          PRML-Kernel PCA
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-06-20 01:05:11" itemprop="dateCreated datePublished" datetime="2021-06-20T01:05:11+08:00">2021-06-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-07-20 20:00:12" itemprop="dateModified" datetime="2021-07-20T20:00:12+08:00">2021-07-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ml/" itemprop="url" rel="index"><span itemprop="name">ml</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/06/20/PRML-Kernel-PCA/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/06/20/PRML-Kernel-PCA/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.9k</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>好久没写博客了，之前一直在做RelexNet的项目，感觉上是做出了一些还不错的东西，也不知道能不能发一篇论文。这个学期选了anu Statistic Machine Learning这门以前的神课，当然感觉现在好像没有以前那种难度的感觉了，但结合这门课加上PRML这本书的学习，也从数学的角度更好的理解了一些机器学习的原理，不得不说Bishop是真的很爱用贝叶斯来解释一切。</p>
<h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>It is a long time for me not writing the Blog. Recently, I just finished my last honours year of bachelor degree and the thesis. I am not sure if the thesis could be published to a conference, but I will trying to do this. In the last semester, I chose the course COMP4670 (Statistical Machine Learning). Although it may be not as difficult as before, I could also learn much knowledge from this course and PRML (Pattern Recognition and Machine Learning) book. From a mathematical point of view, I have a better understanding of some machine learning principles. I have to say that Bishop really likes to use Bayes to explain everything (lol). I would like to update about Kernel method first, the previous chapters can also be updated slowly.</p>
<a id="more"></a>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="What-is-PCA-used-for"><a href="#What-is-PCA-used-for" class="headerlink" title="What is PCA used for?"></a>What is PCA used for?</h2><p>Since we want to know about Kernel PCA, the first step is to understand about PCA. PCA is called principal component analysis, a method used to dimensionality reduction. Its purpose is to find the components that best represent the data. In the field of machine learning, the data we use is usually large and multidimensional. It is complete but often consumes a lot of computing resources for training model. What PCA doing is to reduce the dimensionality of the data while maintaining the main features of the data. Just like if we cannot afford Burberry’s trench coat, we could buy the Uniqlo’s, which only takes One-thirtieth price of Burberry’s. This really saves a lot. Another important role is that PCA can make the data linearly separable, so that machine learning models could fit and classify the data better.</p>
<h2 id="An-Example-for-PCA"><a href="#An-Example-for-PCA" class="headerlink" title="An Example for PCA"></a>An Example for PCA</h2><img src="/2021/06/20/PRML-Kernel-PCA/1.png" class title="[Linear separable]">  
<p>Let’s take an example. For the iris dataset (from sklearn package), it has a total of 150 samples, 4 dimensions, and 3 classes. We can use PCA to reduce the data to 2-dimension space and seen in the figure that the decision boundaries are obvious and the model could roughly distinguish the data.</p>
<h1 id="Limits-of-PCA"><a href="#Limits-of-PCA" class="headerlink" title="Limits of PCA"></a>Limits of PCA</h1><img src="/2021/06/20/PRML-Kernel-PCA/2.png" class title="[Non-linear inseparable]">
<p>So PCA is mainly to eliminate the correlations between variables and assume that the correlations are linear. However, good results cannot be obtained for non-linear dependencies between data. In question2 of assignment2, as shown in the figure, we need to make the data composed of rings linearly separable. It is difficult for us to divide different rings with linear decision boundaries.</p>
<h1 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h1><h2 id="Basic-function"><a href="#Basic-function" class="headerlink" title="Basic function"></a>Basic function</h2><p>So there are 3 solutions I will introduce. The first is basic function. Simply speaking, the basic function makes the data linearly separable by reconstructing the original data in high-dimensional space. </p>
<script type="math/tex; mode=display">\phi([x_1, x_2]^T) = [x_1^2, x_2^2, \sqrt{2}x_1x_2]^T \tag 1</script><p>For example, like the first basic function shown in the formula 1, it forms a new 3-d feature space and in the figure we could find the linear decision boundary flats easily.</p>
<img src="/2021/06/20/PRML-Kernel-PCA/3.png" class title="[3D Linear separable]"> 
<p>If the number of feature dimension of the basic function exceeds 3, we can use PCA to remap it back to a two-dimensional space, like the second basic function of formula 2. </p>
<script type="math/tex; mode=display">\phi(x) = (x_1^3, x_2^3, \sqrt{3}x_1x_2^2, \sqrt{3}x_1^2x_2, 3x_1^2, 3x_2^2, 3\sqrt{2}x_1x_2, 3\sqrt{3}x_1, 3\sqrt{3}x_2, 3\sqrt{3}) \tag 2</script><p>However, the disadvantage of doing this is that calculating the covariance matrix will consume a lot of computing resources. Besides the inner product of some basic functions cannot be displayed explicitly.</p>
<h2 id="Kernel-PCA"><a href="#Kernel-PCA" class="headerlink" title="Kernel PCA"></a>Kernel PCA</h2><p>At that time, I realized that since we only need the covariance matrix and eigenvectors of the basic functions, we can use a more effective way to obtain them. That is the kernel PCA method. First of all, because we want to use the Kernel method to implement Kernel PCA, we need to transform the problem from finding the eigenvalues and eigenvectors of the Covariance Matrix (formula 3) to the Kernel Matrix (formula 4). </p>
<script type="math/tex; mode=display">C = \sum_{N} \phi(x_i) \phi(x_i)^\top \tag 3</script><script type="math/tex; mode=display">K = \sum_{N} \phi(x_i)^\top \phi(x_i)</script><script type="math/tex; mode=display">= \begin{pmatrix}
    \phi(x_1)^\top\phi(x_1) & \cdots & \phi(x_1)^\top\phi(x_N)\\
    \vdots & \ddots & \vdots\\
    \phi(x_N)^\top\phi(x_1) & \cdots & \phi(x_N)^\top\phi(x_N)\\
    \end{pmatrix}</script><script type="math/tex; mode=display">= \begin{pmatrix}
    k(x_1, x_1) & \cdots & k(x_1, x_N)\\
    \vdots & \ddots & \vdots\\
    k(x_N, x_1) & \cdots & k(x_N, x_N)\\
    \end{pmatrix} \tag 4</script><p>And each element of K Matrix is the inner product between each basic vector. The basic function of formula 2 has been transformed into such a simple product form (formula 5), also called the complete polynomial kernel function. </p>
<script type="math/tex; mode=display">\mathbf{k}(\mathbf{x_i}, \mathbf{x_j}) = \phi(x_i)^\top\phi(x_j) = (\mathbf{x_i}^\top \mathbf{x_j} + 3)^3 \tag 5</script><p>After finding the eigenvectors and eigenvalues of K (formula 6), we need to transform it to the value of covariance matrix(formula 7), which only need to multiply the transpose of the basic vector on both sides of the eigen equation of K Matrix. Then the eigenvalues and eigenvectors of the covariance matrix can be obtained. </p>
<script type="math/tex; mode=display">\mathbf{K} \cdot \mathbf{v_j} = \mathbf{\lambda_j} \cdot \mathbf{v_j} \Rightarrow \mathbf{\phi(X)} \mathbf{\phi(X)^\top} \cdot \mathbf{v_j} = \mathbf{\lambda_j} \cdot \mathbf{v_j} \tag 6</script><script type="math/tex; mode=display">\downarrow</script><script type="math/tex; mode=display">(\mathbf{\phi(X)}^\top \mathbf{\phi(X)}) \cdot (\mathbf{\phi(X)}^\top \mathbf{v_j}) = \mathbf{\lambda_j} \cdot(\mathbf{\phi(X)}^\top \mathbf{v_j})</script><script type="math/tex; mode=display">\downarrow</script><script type="math/tex; mode=display">\mathbf{C} \cdot (\mathbf{\phi(X)^\top} \mathbf{v_j}) = \mathbf{\lambda_j} \cdot(\mathbf{\phi(X)^\top} \mathbf{v_j})</script><script type="math/tex; mode=display">\downarrow</script><script type="math/tex; mode=display">\text{Assume} \space \mathbf{u_j} = \mathbf{\phi(X)^\top} \mathbf{v_j}, \space C \cdot \mathbf{u_j} = \mathbf{\lambda_j} \cdot \mathbf{u_j} \tag 7</script><h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><p>And there are some tips that may cause mistakes, which I have met before.  </p>
<ol>
<li>The first is do not mess up Kernel matrix and Covariance matrix, they look similar, but are not equal. </li>
<li>The second is that we need to make zero average to matrix K. But Don’t straightly make zero average to matrix K, because what we really want to do is zero averaging basic function. We need to use basic function to derive zero averaging of matrix K (formula 8).  </li>
</ol>
<script type="math/tex; mode=display">\bar K = (\phi(x) - \overline{\phi(x)})^\top (\phi(x) - \overline{\phi(x)}) = K - I_NK - KI_N +I_NKI_N \tag 8</script><ol>
<li><p>Besides, we should normalize the eigenvectors. Remember, we need to normalize the eigenvector of Covariance Matrix not Kernel Matrix (formula 9).  </p>
<script type="math/tex; mode=display">1 = u_j^\top u_j = v_j^\top \phi(X)\phi(X)^\top v_j = v_j^\top K v_j = \lambda_j v_j^\top v_j</script><script type="math/tex; mode=display">\downarrow</script><script type="math/tex; mode=display">v_j = \frac{1}{\sqrt \lambda} v_{j\_origin} \tag 9</script></li>
<li><p>Last but not least, do not forget to project the data. Even if we don’t get the basic function, we could use the formula to derive the solution by multiply Kernel matrix and eigenvectors of Kernel matrix.</p>
</li>
</ol>
<script type="math/tex; mode=display">\text{projected} = \phi(x)^\top u_j = \phi(x)^\top \phi(x)v_j =Kv_j  \tag {10}</script><h2 id="Different-Kernel-Function"><a href="#Different-Kernel-Function" class="headerlink" title="Different Kernel Function"></a>Different Kernel Function</h2><img src="/2021/06/20/PRML-Kernel-PCA/6.png" class title="[Three Kernel Function]">
<p>Different choices of kernel function will have different results. If we use the kernel function in the previous slides, which is called the complete polynomial kernel function, the ring dataset cannot be divided. Therefore, at the end of the question 2 of assignment 2, we use the RBF kernel function, which often cannot be expressed explicitly by the basic function. After adjusting the value of gamma in RBF kernel function, we can see that the ring data set can be well linearly separated.</p>
<h2 id="Nerual-Network-Method"><a href="#Nerual-Network-Method" class="headerlink" title="Nerual Network Method"></a>Nerual Network Method</h2><p>The neural network method was inspired by the logistic regression problem of assignment 1. In assignment 1, we can draw the decision boundary of the XOR problem by inputting the basic function, adjusting the number of hidden numbers and using the sigmoid activation function. I consider if the number of hidden neurons is 2 and the model could be fitted well, then in this two-dimensional space, the decision boundary should be linear. Therefore, I set up a neural network with the architecture. </p>
<img src="/2021/06/20/PRML-Kernel-PCA/7.png" class title="[Nerual Network]">
<p>I adjusted the input to new 3-d features, which may present the circle data well. Then Set two latent variables in hidden layer and add the sigmoid activation function. Finally, the model is optimized by predicting the label. The final result is shown in the figure, and we can clearly find the decision boundaries.</p>
<img src="/2021/06/20/PRML-Kernel-PCA/8.png" class title="[Nerual Network Decision Boundary]">

    </div>

    
    
    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

      
    </div>

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/course/" rel="tag"># course</a>
              <a href="/tags/ml/" rel="tag"># ml</a>
              <a href="/tags/prml/" rel="tag"># prml</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/08/04/COMP4650-Document-Analysis-Ranked-Retrieval/" rel="prev" title="COMP4650(Document Analysis) Ranked Retrieval">
      <i class="fa fa-chevron-left"></i> COMP4650(Document Analysis) Ranked Retrieval
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/07/13/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%84%9F%E7%9F%A5%E6%9C%BA/" rel="next" title="统计学习方法-感知机">
      统计学习方法-感知机 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Preface"><span class="nav-number">2.</span> <span class="nav-text">Preface</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">3.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#What-is-PCA-used-for"><span class="nav-number">3.1.</span> <span class="nav-text">What is PCA used for?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#An-Example-for-PCA"><span class="nav-number">3.2.</span> <span class="nav-text">An Example for PCA</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Limits-of-PCA"><span class="nav-number">4.</span> <span class="nav-text">Limits of PCA</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Solution"><span class="nav-number">5.</span> <span class="nav-text">Solution</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Basic-function"><span class="nav-number">5.1.</span> <span class="nav-text">Basic function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kernel-PCA"><span class="nav-number">5.2.</span> <span class="nav-text">Kernel PCA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tips"><span class="nav-number">5.3.</span> <span class="nav-text">Tips</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Different-Kernel-Function"><span class="nav-number">5.4.</span> <span class="nav-text">Different Kernel Function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Nerual-Network-Method"><span class="nav-number">5.5.</span> <span class="nav-text">Nerual Network Method</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="永缘空"
      src="/images/header.jpg">
  <p class="site-author-name" itemprop="name">永缘空</p>
  <div class="site-description" itemprop="description">山东大学17级计算机科学与技术，澳大利亚国立大学Bachelor of Advanced Computing(Honors), 澳大利亚国立大学Master of Machine Learning and Computer Vision主要学习NLP, Machine Learning等机器学习领域，此为个人博客。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2020 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">永缘空</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">35k</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,0' opacity='0.5' zIndex='-1' count='150' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : true,
      appId      : 'mDMP1YcO9YbOcBLneAjQaJuj-gzGzoHsz',
      appKey     : 'h9IkJ3I6bmAT2UG64PFMm7KI',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/clicklove.js"></script>

</body>
</html>

<!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/clicklove.js"></script>
